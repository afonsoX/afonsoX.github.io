---

layout:     post
title:      "python爬虫入门(二)"
SEOTitle:   阿翔的博客|AShane's Blog
subtitle:   "python爬虫的基础知识整理"
date:       2017-07-22
author:     "AShane"
header-img: "img/python-WebSpider2.jpg"
catalog: true
tags:
    - python
    - 爬虫
    - 入门   
---

> “ To be continued …” 

> **关键字**：[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html), python ,re

# 前言
---
Beautiful Soup 是一个可以从HTML或XML文件中提取数据的Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式. -- Beautiful Soup 4.2.0 文档

# 正文
---
## BeautifulSoup 入门

`from bs4 import BeautifulSoup`
`soup = BeautifulSoup('<p>data</p>','html.parser')`

#### bs4库的基本元素：

```
import requests
from bs4 import BeautifulSoup

r = requests.get("http://python123.io/ws/demo.html")
demo = r.text
soup = BeautifulSoup(demo, 'html.parser')
print(soup.prettify())  #soup.prettify()会在每个标签加\n
```
BeautifulSoup库使解析、便利、维护“标签树”的功能库

#### BeautifulSoup库解析器

解析器 | 使用方法 | 条件
------|--------|-----
bs4的HTML解析器| BeautifulSoup(mk,'html.parser')|安装bs4
lxml的HTML解析器| BeautifulSoup(mk,'lxml')|pip install lxml
lxmk的XML解析器|BeautifulSoup(ml,'xml')|同上
html5lib的解析器|BeautifulSoup(mk,'html5lib')|pip install html5lib

#### BeautifulSoup类的基本元素

基本元素|说明
-----|---
Tag|标签，soup.<tag>返回第一个
Name|标签的名字
Attributes|标签的属性，**字典形式**组织
NavigableString|标签内非属性字符串，<>...</>中的字符串
Comment|标签内字符串的注释部分

#### 标签树的下行遍历
属性|说明
----|---
.contents|(列表)将<tag>所有**儿子**节点存入列表
.children|(迭代类型)用于循环遍历**儿子**节点
.descendants|(迭代类型)包含所有**子孙**节点
> BeautifulSoup类型是标签树的根节点

> NavigableString也算一个儿子节点

#### 标签树的上行遍历
属性|说明
----|---
.parent|节点的父亲标签
.parents|(迭代类型)用于循环便利先辈节点

```
例：
for parent in soup.a.parents:
	if parent is None:
		print(parent) #soup本身也会出现，但soup不具有name属性
	else:
		print(parent.name)
输出：
p
body
html
[document]
```
> html的父亲为soup本身，即[document]

#### 标签树的平行遍历

属性|说明
---|---
.next_sibling|返回HTML文本顺序的下一个平行节点标签
.previous_sibling|返回HTML文本顺序上一个平行节点标签
.next_siblings|(迭代类型)返回后续所有平行节点
.previous_siblings|(迭代类型)返回前序所有平行节点

> 平行遍历发生在同一个父亲节点的各个节点之间

```
例：
for sibling in soup.a.next_sibling:
	print(sibling)

for sibling in soup.a.previous_sibling:
	print(sibling)
```
#### 使HTML页面内容展示更友好
使用bs4库的prettify()方法
> .prettify()方法为标签及内容增加'\n',用print()输出后更直观
> > .prettify()方法也可单独用于标签`<tag>.prettify()`

#### bs4库的编码
bs4库将任何HTML输入都变成utf-8编码，Python3.x默认支持utf-8编码

#### bs4库find方法
方法|说明
---|---
<>.find() | 搜索且返回一个结果，同.find_all()参数
<>.find_parents()|在先辈节点中搜索，返回列表类型同.find_all()参数
<>.find_parent()|在先辈节点种返回一个结果，同.find()参数
<>.find\_next_siblings()|在后续节点中搜索，返回列表类型，同.find_all()参数
<>.find\_next_sibling()|在后续平行节点中返回一个结果，同.find()参数
<>.find\_previous_siblings()|在前序平行节点中搜索，返回列表类型，同.find()参数
<>.find\_previous_sibling()|在前序平行节点中返回一个结果，同.find()参数

> <>.find_all(name, attrs, recursive, string, **kwargs)

```
	name : 可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉
	attrs : 对标签属性值检索字符串，可标注属性检索(如：id='')
	recursive : 是否对子孙全部检索，默认True
	string : <>...</>中字符串区域的检索字符串
```
-  \<tag>(..) 等价于 \<tag>.find_all(..)
-  soup(..) 等价于 soup.find_all(..)

> get_text() 得到标签中包含的内容

```
import requests
from bs4 import BeautifulSoup
import re

demo = requests.get('http://python123.io/ws/demo.html').text
soup = BeautifulSoup(demo,'html.parser')

soup.find_all('a')

for tag in soup.find_all('a'):   #列表类型逐个打印
	print(tag)

for tag in soup.find_all(re.compile('b')): #包含b的标签
	print(tag.name)      #输出包含body标签

for tag in soup.find_all('a', recursive=False):   #列表类型逐个打印
	print(tag)	

soup.find_all(string = 'Basic Python')

soup.find_all(string = re.compile('python'))

soup(string = 'Python')

soup(string = re.compile('Python')

```

## 信息标记和提取

#### XML (eXtensive Makeup Language)
```
	<name>...</name>
		一般形式
	<name />
		空元素的缩写形式
	<!-- -->
		注释
```

#### JSON （JavaScript Object Notation）
```
有类型键值对：
	"key" : "value"
		一般形式
	"key" : ["value1" : "value2"]
		多值用[,]组织
	"key" : {
				"key1" : "value1",
				"key2" : "value2"
			  }
		键值对嵌套使用{,}	
```

#### YAML (Ain't Markup Language)
```
无类型键值对：
	key : value     ---仅字符串
		一般形式
	key : 
		subkey1 : value1
		subkey2 : value2
		缩进表达所属关系
	key :
	- value1
	- value2
		并列关系
	key :  |text
		整个数据块
	key : #comment
		注释
```
##### 三种信息标记形式比较
名称 | 说明 | 主要用途
--- | --- |---
XML | 最早的通用信息标记语言，拓展性好|Internet上信息交互与传递
JSON|有类型信息，较简洁，无注释|移动云端和节点信息通信
YAML|无类型信息，很简洁，可读性高，有注释|各类系统配置文件

## 实例

### “软科”中国大学排名定向爬虫
爬虫网址`http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html`
功能描述：
```
输入： 大学排名URL链接
输出： 大学拍哦明信息的屏幕输出(排名，大学名称，总分)

技术路线：requests-bs4
定向爬虫：仅对输入URL进行爬取，部拓展爬取

可行性：1 http://www.zuihaodaxue.cn/robots.txt 无内容
		2 所有信息在<tbody>标签之下
```
执行代码：

```
import requests
from bs4 import BeautifulSoup
import bs4

# 从网站上获取大学排名网页内容 
def getHTMLText(url):
    try:
        r = requests.get(url, timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        print( "HTMLError %d" %r.status_code )

# 提取网页内容中信息到合适的数据结构 
def fillUnivList(ulist, html):
    soup = BeautifulSoup(html, "html.parser")
    for tr in soup.find('tbody').children:
        if isinstance(tr, bs4.element.Tag): #去掉空信息
            tds = tr('td')
            ulist.append([tds[0].string, tds[1].string, tds[3].string])

#利用数据结构展示并输出结果 
def printUnivList(ulist, num):
    tplt = "{0:^10}\t{1:{3}^10}\t{2:^10}"
    print(tplt.format("排名","学校名称","总分",chr(12288)))
    for i in range(num):
        u=ulist[i]
        print(tplt.format(u[0],u[1],u[2],chr(12288))) #解决中英文混排输出
     
def main():
    uinfo = []
    url = 'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html'
    html = getHTMLText(url)
    fillUnivList(uinfo, html)
    printUnivList(uinfo, 20) # 20 univs
main()

```

#### format格式
![format](http://ot6qg4j9m.bkt.clouddn.com/Format%27s%20Pic.png?imageslim)
中文对齐问题的原因：当中文字符宽带不够时，默认采用西文字符填充，中西文字符占用宽带不同。**解决办法**：采用中文字符的空格填充**chr(12288)**