---

layout:     post
title:      "python爬虫"
SEOTitle:   阿翔的博客|AShane's Blog
subtitle:   "使用pyenv管理多个python版本"
date:       2017-07-19
author:     "AShane"
header-img: "img/post-bg-unix-linux.jpg"
catalog: true
tags:
    - python
    - 爬虫
    - 入门   
---

> “ To be continued …” 

> **关键字**：[requests](http://docs.python-requests.org/en/master/), python

# 前言
---
**Requests** is an elegant and simple HTTP library for Python, safe for human consumption . -- from [docs of requests](http://docs.python-requests.org/en/master/)

# 正文
---

## 基础
### HTTP协议
HTTP协议(Hypertext Transfer Protocol，超文本传输协议)是一个基于“请求与响应”模式的、无状态的应用层协议.
　`http://host[:port][path]`

- host:合法的Internet主机域名或IP地址

- port:端口号，缺省端口为80

- path:请求资源的路径

方法    | 说明 
-----  |-----
GET    |请求获取URL位置的资源HEAD   |请求获取URL位置资源的响应消息报告，即获得该资源的头部信息
POST  |请求向URL位置的资源后附加新的数据PUT    |请求向URL位置存储一个资源，覆盖原URL位置的资源PATCH  |请求局部更新URL位置的资源，即改变该处资源的部分内容
DELETE |请求删除URL位置存储的资源
>其中GET和HEAD是获取资源，其他为存储／修改／删除资源

### Requests库的主要方法
- `requests.request()`构造一个请求，支撑一下个方法的基础方法
- `requests,get()`获取HTML网页的主要方法，对应HTTP的GET
- `requests.head()`获取HTML网页头信息，对应HTTP的HEAD 
	- HEAD请求所要与GET一致的响应，但是相应体不返回
- `requests.post()`向HTML网页提交Post请求，对应HTTP的POST
- `requests.put()`向HTML网页提交Put请求，对应HTTP的PUT
- `requests.patch`向HTML网页提交局部修改请求，对应HTTP的PATCH
- `requests.delete()`向HTML网页提交删除请求，对应HTTP的DELETE

### 部分方法使用
1.requests.request()方法见官方：
> r = requests.request('GET', url, **kwargs)

![requests.request()](http://ot6qg4j9m.bkt.clouddn.com/requests.request.png?imageslim)

2.get()方法
> requests.get(url,params=None,**kwargs)

	params : 字典或字节序列，作为参数增加到url中
	**kwards为12个控制访问的参数:	
		data : 字典、字节序列或文件对象，作为Request的内容 
		json : JSON格式的数据，作为Request的内容
		headers : 字典，HTTP定制头
		cookies : 字典或CookieJar，Request中的cookie		auth : 元组，支持HTTP认证功能
		files : 字典类型，传输文件		timeout : 设定超时时间，秒为单位		proxies : 字典类型，设定访问代理服务器，可以增加登录认证
		allow_redirects : True/False，默认为True，重定向开关 		stream : True/False，默认为True，获取内容立即下载开关 		verify : True/False，默认为True，认证SSL证书开关		cert : 本地SSL证书路径
	实际调用request('get',url,params=params,**kwargs)

3.head()、post()、put()方法

- head()：r.headers返回头部信息
	![head](http://ot6qg4j9m.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-07-19%20%E4%B8%8B%E5%8D%882.14.17.png?imageslim)
- post():data参数为一个字典值，编码为form表单提交
	![post1](http://ot6qg4j9m.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-07-19%20%E4%B8%8B%E5%8D%882.24.37.png?imageslim)
- post():data参数为字符串，编码为data提交
	![post2](http://ot6qg4j9m.bkt.clouddn.com/post%E6%96%B9%E6%B3%952.png?imageslim)
- post():json参数为字典值，编码为data键值对提交
	![post3](http://ot6qg4j9m.bkt.clouddn.com/post_json.png?imageslim)
- put()
	![put](http://ot6qg4j9m.bkt.clouddn.com/put%E6%96%B9%E6%B3%95%202017-07-19%20.png?imageslim)
- post():修改头部信息(可用chrome/10;mozilla/5等)
 	![header](http://ot6qg4j9m.bkt.clouddn.com/header%20%E4%B8%8B%E5%8D%883.08.24.png?imageslim)
	
### Response对象属性
- `r.status_code` HTTP请求返回的类型：
	- 200/OK；
	- 202/Accepted；
	- 400/Bad Request；
	- 403/Forbidden；
	- 404/Not Found；
- `r.text` HTTP相应内容的字符串形式
	- 可以用[:1000]or[-1000:]来读取大信息量返回数据
- `r.encoding `从HTTP Header中解析的响应内容编码
	- 若header中不存在charset，则认为是ISO-8859-1(不显示中文)
	- 用 `r.recoding = r.apparent_encoding`
	- `r.apparent_encoding`是内容展示编码
- `r.content` HTTP响应内容的二进制形式	
- `r.request.headers`
- `r.request.url`
- `len(r.text)`	

### Requests库的异常

- `requests.connectionError`网络连接异常：DNS查询失败等
- `requests.HTTPError` HTTP错误异常
- `requests.URLRequired` URL缺失异常
- `requests.TooManyRedirects` 超过最大重定向次数，产生重定向异常
- `requests.ConnectTimeout` 连接远程服务器超时异常
- `requests.Timeout` 请求URL超时，产生超时异常

**Response捕获异常**`r.raise_for_status()`若返回不是200则捕获*requests.HTTPError*异常

### 通用代码框架

```
import requests

def getHTML(url) :

 try :
	 r = requests.get(url,timeout=30)
	 r.raise_for_status()
	 r.encoding = r.apparent_encoding
	 return r.text
 except :
 	return "HTTPError"
 	
 if __name__=="__main()__" :
 	url = "http://www.baidu.com"
 	print(getHTMLText(url))
```
[关于`if __name__=="__main()__" :"`的使用](#__name__)
<p id = "return0"></p>
 
## 网络爬虫的尺寸
小规模，数据量小 爬取速度不敏感 |中规模，数据规模较大 爬取速度敏感 |大规模，搜索引擎 爬取速度关键
----|----|----Requests库|**Scrapy库**|定制开发
爬取网页|爬去系列网页|爬取全网 

## 网络爬虫限制
- 来源审查：判断User-Agent进行限制：如Amazon
	- 检查来访HTTP协议头的User-Agent,只想赢浏览器和友好爬虫
- 发布公告：Robots协议：网站根目录下的robots.txt
	- <http://www.jd.com/robots.txt>
	- <http://www.baidu.com/robots.txt>
	- <http://news.qq.com/robots.txt> 	
	- <http://www.qq.com/robots.txt>
	- 教育部： http://www.moe.edu.cn/robots.txt (无robots协议)

### 爬亚马逊商城
爬取亚马逊商城时返回503错误，r.text中出现`please contact api-services-support@amazon.com,for imformation about migrating to our APIs ...` 这是需要修改头部信息。

```
import requests

url = "https://www.amazon.cn/kindle-store/dp/B00QJDOLIO/ref=sr_1_2?ie=UTF8&qid=1500462821&sr=8-2&keywords=kindle"
hd = {'user-agent' : 'mozilla/5.0'}
try:
    r = requests.get(url,timeout = 30,headers = hd);
    r.raise_for_status()
    r.encoding = r.apparent_encoding
    print(r.text[1000:3000])
except:
    print("HTTPError : %d" % r.status_code)
```
### 搜索引擎关键字提交接口
- 百度的关键词接口:http://www.baidu.com/s?wd=*keyword* 
- 360的关键词接口:http://www.so.com/s?q=*keyword*

```
import requests

url = "http://www.baidu.com/s?"
kv = {"wd" : "python3.6"}
try :
    r = requests.get(url,params = kv)
    r.raise_for_status()
    if __name__ == '__main__':
    	print(r.request.url)
    	print(len(r.text))
    print(r.text[:1000])
except :
    print("HTTPError %d" % r.status_code())
```

<p id = 'return1'></p>

### 网络图片爬取

[OS库介绍](#os)

[with as ](#with)

[文件操作](#fileOperate)

```
import requests
import os

url = "http://image.nationalgeographic.com.cn/2015/0122/20150122055308561.jpg"
root = '/Users/afonso/python3.6/'
path = root + url.split('/')[-1]
try:
    if not os.path.exists(root):
        os.mkdir(root)
    if not os.path.exists(path):
        r = requests.get(url)
        r.raise_for_status()
        with open(path,'wb') as f:
            f.write(r.content)
            prinf("save successfully")
    else:
        print("the file has existed")
except:
    print("HTTPError %d" % r.status_code)
```
 
 <p id = "__name__"></p>
#### if __name__=="__main__" :使用 
 一个python文件主要有两个实用方法：
 - 直接作为脚本执行
 - import到其他的python脚本中被调用(模块重用)执行
 而`if __name__=="__main__" :`的作用就是控制执行代码的过程.**当py文件作为脚本直接运行时满足if条件，当被import到其他文件时则不会被执行。**
 
```
#module.py
def main():
	print("__name__ is %s" % __name__) #python3.X
	print("__name__ is %s") % (__name__) #python2.X
if __name__ == '__main__':
	main()
```
输出 \_\_name__ is \_\_main__

```
#module_name.py
from module import main
main()
print(__name__)
```
输出 \_\_name__ is **module** ； \_\_main__
> 1.当import导入该文件时，__name__为py文件名

> 2.使用`if __name__ == '__main__':`可以再文件中加入调试模块，当被导入其他文件时不被执行二排查问题直接执行模块时调试代码能正常运行。[返回](#return0)

<p id='os'></p>

#### OS库介绍：

> OS模块简单来说是一个Python的系统编程的操作模块，可以处理文件和目录这些我们日常手动需要做的操作。[返回](#return1)

```
	os.getcwd() 获取当前目录的绝对地址
	os.chdir() 改变当前路径到指定路径
	os.listdir() 返回指定目录下的所有目录和文件
		name = os.listdir(pwd)
		for filename in name:
			print(filename)
	os.remove('file.txt') 删除指定文件
	os.removedirs('file') 删除目录文件
	os.shell('ls -a > 1.txt')执行shell命令
	os.mkdir('file') 创建一个新目录
	os.path.isfile('file') 判断是不是文件
	os.path.isdir('dir') 判断是否为目录
	os.path.exists('file') 判断是否存在
	os.path.splitext('file') 分离文件名和拓展名
	os.path.split('name') 分割文件名和目录
	os.path.basename('path') 返回文件名
	os.path.dirname('path') 返回文件路径
	help(os) 查看os帮助文档
```

<p id='with></p>

#### with as 语法被用来替代 try finally

> with所求值必须有一个\_\_enter\_\_()方法，一个\_\_exit__()方法。[返回](#return1)

```
file = open("/tmp/foo.txt")  
try:  
    data = file.read()  
finally:  
    file.close()  
```
替换为

```
with open("/tmp/foo.txt") as file:  
    data = file.read() 
```

自定义：

```
class Sample:  
    def __enter__(self):  
        print "In __enter__()"  
        return "Foo"  
   
    def __exit__(self, type, value, trace):  
        print "In __exit__()"  
   
   
def get_sample():  
    return Sample()  
   
   
with get_sample() as sample:  
    print "sample:", sample  
==================================    
输出：
In __enter__()  
sample: Foo  
In __exit__()  

```

<p id='fileOperate'></p>

### python文件操作
**f = open('pwd',读写模式)**

```
w     以写方式打开，
a     以追加模式打开 (从 EOF 开始, 必要时创建新文件)
r+     以读写模式打开
w+     以读写模式打开 (参见 w )
a+     以读写模式打开 (参见 a )
rb     以二进制读模式打开
wb     以二进制写模式打开 (参见 w )
ab     以二进制追加模式打开 (参见 a )
rb+    以二进制读写模式打开 (参见 r+ )
wb+    以二进制读写模式打开 (参见 w+ )
ab+    以二进制读写模式打开 (参见 a+ )
```
> 使用 w 写方式打开，文件若存在，首先清空再重载
> 使用 a 追加方式会吧所有写入文件末尾，若文件不存在将会被自动创建

- **f.read([size])** size未指定则返回整个文件,如果文件大小>2倍内存则有问题.f.read()读到文件尾时返回""(空字串)

- **file.readline()** 返回一行

- **file.readlines([size])** 返回包含size行的列表,size 未指定则返回全部行

	- **for line in file.readlines(): line.strip()** #通过迭代器访问

- **f.write("hello\n")** #如果要写入字符串以外的数据,先将他转换为字符串.

- **f.tell()** 返回一个整数,表示当前文件指针的位置(就是到文件头的比特数).

- **f.seek(偏移量,[起始位置])** 用来移动文件指针.偏移量:单位:比特,可正可负.起始位置:0-文件头,默认值;1-当前位置;2-文件尾

- **f.close()** 关闭文件

- [返回](#return1)
